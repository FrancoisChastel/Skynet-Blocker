{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ds4ml import DataSet\n",
    "from src.protos import skynet_pb2\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/darkraven/Dev/github.com/Fluximmo/notebook-experiments/data/2022.csv '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/darkraven/Dev/github.com/FrancoisChastel/Skynet-Blocker/results.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/darkraven/Dev/github.com/FrancoisChastel/Skynet-Blocker/results.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/Users/darkraven/Dev/github.com/Fluximmo/notebook-experiments/data/2022.csv \u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file_in:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darkraven/Dev/github.com/FrancoisChastel/Skynet-Blocker/results.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_in,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/darkraven/Dev/github.com/FrancoisChastel/Skynet-Blocker/results.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                       low_memory\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, float_precision\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m, skipinitialspace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/darkraven/Dev/github.com/Fluximmo/notebook-experiments/data/2022.csv '"
     ]
    }
   ],
   "source": [
    "with open('/Users/darkraven/Dev/github.com/Fluximmo/notebook-experiments/data/2022.csv', 'rb') as file_in:\n",
    "    df = pd.read_csv(file_in,\n",
    "                      low_memory=False, float_precision='high', encoding='latin1', skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/Users/darkraven/Dev/github.com/Fluximmo/notebook-experiments/data/dvf/cleaned.csv', 'rb') as file_in:\n",
    "    df = pd.read_csv(file_in,\n",
    "                      low_memory=False, float_precision='high', encoding='latin1', skipinitialspace=True)\n",
    "    before_attrs = set(df.columns)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    after_attrs = set(df.columns)\n",
    "    if len(before_attrs) > len(after_attrs):\n",
    "        print(\n",
    "            f'Empty columns are removed, include {before_attrs - after_attrs}.')\n",
    "    # Remove rows with all empty values\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    df.drop(columns='dvf_type_local', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = {'dvf_valeur_fonciere': protos.ColType.ColType_Float64, 'PriceSizeRatio': protos.ColType.ColType_Float64,\n",
    "       'dvf_code_postal': protos.ColType.ColType_Float64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anonypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [68], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m sensitive_column \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdvf_valeur_fonciere\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m p \u001b[39m=\u001b[39m anonypy\u001b[39m.\u001b[39mPreserver(df, feature_columns, sensitive_column)\n\u001b[0;32m----> 9\u001b[0m rows \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49manonymize_k_anonymity(k\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m dfn \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(rows)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(dfn)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/anonypy/anonypy.py:18\u001b[0m, in \u001b[0;36mPreserver.anonymize_k_anonymity\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manonymize_k_anonymity\u001b[39m(\u001b[39mself\u001b[39m, k):\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__anonymize(k)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/anonypy/anonypy.py:10\u001b[0m, in \u001b[0;36mPreserver.__anonymize\u001b[0;34m(self, k, l, p)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__anonymize\u001b[39m(\u001b[39mself\u001b[39m, k, l\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m):\n\u001b[1;32m      9\u001b[0m     partitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodrian\u001b[39m.\u001b[39mpartition(k, l, p)\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m anonymize(\n\u001b[1;32m     11\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodrian\u001b[39m.\u001b[39;49mdf,\n\u001b[1;32m     12\u001b[0m         partitions,\n\u001b[1;32m     13\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodrian\u001b[39m.\u001b[39;49mfeature_columns,\n\u001b[1;32m     14\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodrian\u001b[39m.\u001b[39;49msensitive_column,\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/anonypy/anonypy.py:79\u001b[0m, in \u001b[0;36manonymize\u001b[0;34m(df, partitions, feature_columns, sensitive_column, max_partitions)\u001b[0m\n\u001b[1;32m     75\u001b[0m grouped_columns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[partition]\u001b[39m.\u001b[39magg(aggregations, squeeze\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m sensitive_counts \u001b[39m=\u001b[39m (\n\u001b[1;32m     77\u001b[0m     df\u001b[39m.\u001b[39mloc[partition]\u001b[39m.\u001b[39mgroupby(sensitive_column)\u001b[39m.\u001b[39magg({sensitive_column: \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m values \u001b[39m=\u001b[39m grouped_columns\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto_dict()\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m sensitive_value, count \u001b[39min\u001b[39;00m sensitive_counts[sensitive_column]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m count \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "\n",
    "for name in [used_col for used_col in used_cols.keys(\n",
    "    ) if (used_cols[used_col] == protos.ColType.ColType_Category)]:\n",
    "    df[name] = df[name].astype(\"category\")\n",
    "\n",
    "feature_columns = [\"dvf_code_postal\", \"PriceSizeRatio\"]\n",
    "sensitive_column = \"dvf_valeur_fonciere\"\n",
    "\n",
    "p = anonypy.Preserver(df, feature_columns, sensitive_column)\n",
    "rows = p.anonymize_k_anonymity(k=2)\n",
    "p.anonymize_l_diversity(k)\n",
    "p.anonymize_t_closeness\n",
    "dfn = pd.DataFrame(rows)\n",
    "print(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anonypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting AnonyPy\n",
      "  Downloading anonypy-0.1.7-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: AnonyPy\n",
      "Successfully installed AnonyPy-0.1.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install AnonyPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(df: pd.DataFrame, config: protos.NaiveStrategy, request: protos.AnonimiseRequest) -> pd.DataFrame:\n",
    "    anonimised_df = dfAnonymizer(df=df)\n",
    "    \n",
    "    for categorical_col in config.categorical_cols.keys():\n",
    "        anonimisation_strategy = config.categorical_cols[categorical_col]\n",
    "        if anonimisation_strategy == protos.CategoricalAnonimisation.CATEGORICAL_EMAIL_MASKING:\n",
    "            anonimised_df.categorical_email_masking(\n",
    "                columns=categorical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.CategoricalAnonimisation.CATEGORICAL_FAKE:\n",
    "            anonimised_df.categorical_fake(\n",
    "                columns=categorical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.CategoricalAnonimisation.CATEGORICAL_FAKE_AUTO:\n",
    "            anonimised_df.categorical_fake_auto(\n",
    "                columns=categorical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.CategoricalAnonimisation.CATEGORICAL_RESAMPLING:\n",
    "            anonimised_df.categorical_resampling(\n",
    "                columns=categorical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.CategoricalAnonimisation.CATEGORICAL_TOKENIZATION:\n",
    "            anonimised_df.categorical_tokenization(\n",
    "                columns=categorical_col, inplace=True)\n",
    "\n",
    "    for numerical_col in config.numerical_cols.keys():\n",
    "        anonimisation_strategy = config.numerical_cols[numerical_col]\n",
    "        if anonimisation_strategy == protos.NumericAnonimisation.NUMERIC_BINNING:\n",
    "            anonimised_df.numeric_binning(\n",
    "                columns=numerical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.NumericAnonimisation.NUMERIC_MASKING:\n",
    "            anonimised_df.numeric_masking(\n",
    "                columns=numerical_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.NumericAnonimisation.NUMERIC_NOISE:\n",
    "            mean = df['dvf_valeur_fonciere'].mean()/10\n",
    "            anonimised_df.numeric_noise(\n",
    "                columns=numerical_col, inplace=True, MIN=-mean, MIN=mean)\n",
    "        elif anonimisation_strategy == protos.NumericAnonimisation.NUMERIC_ROUNDING:\n",
    "            anonimised_df.numeric_rounding(\n",
    "                columns=numerical_col, inplace=True)\n",
    "\n",
    "    for datetime_col in config.datetime_cols.keys():\n",
    "        anonimisation_strategy = config.datetime_cols[datetime_col]\n",
    "        if anonimisation_strategy == protos.DateTimeAnonimisation.DATETIME_FAKE:\n",
    "            anonimised_df.datetime_fake(\n",
    "                columns=datetime_col, inplace=True)\n",
    "        elif anonimisation_strategy == protos.DateTimeAnonimisation.DATETIME_NOISE:\n",
    "            anonimised_df.datetime_noise(\n",
    "                columns=datetime_col, inplace=True)\n",
    "\n",
    "    return anonimised_df.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetise(df: pd.DataFrame, config: protos.SynthetiseStrategy) -> pd.DataFrame:\n",
    "    dataset = DataSet(df, categories=[used_col for used_col in used_cols.keys(\n",
    "    ) if (used_cols[used_col] == protos.ColType.ColType_Category)])\n",
    "\n",
    "    return dataset.synthesize(epsilon=0.1,\n",
    "                              records=1000, \n",
    "                              pseudonyms=[], \n",
    "                              retains=list(used_cols.keys()),\n",
    "                              deletes=[],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m synthetise(df, \u001b[39mNone\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn [21], line 5\u001b[0m, in \u001b[0;36msynthetise\u001b[0;34m(df, config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msynthetise\u001b[39m(df: pd\u001b[39m.\u001b[39mDataFrame, config: protos\u001b[39m.\u001b[39mSynthetiseStrategy) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m      2\u001b[0m     dataset \u001b[39m=\u001b[39m DataSet(df, categories\u001b[39m=\u001b[39m[used_col \u001b[39mfor\u001b[39;00m used_col \u001b[39min\u001b[39;00m used_cols\u001b[39m.\u001b[39mkeys(\n\u001b[1;32m      3\u001b[0m     ) \u001b[39mif\u001b[39;00m (used_cols[used_col] \u001b[39m==\u001b[39m protos\u001b[39m.\u001b[39mColType\u001b[39m.\u001b[39mColType_Category)])\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39;49msynthesize(epsilon\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                               records\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, \n\u001b[1;32m      7\u001b[0m                               pseudonyms\u001b[39m=\u001b[39;49m[], \n\u001b[1;32m      8\u001b[0m                               retains\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(used_cols\u001b[39m.\u001b[39;49mkeys()),\n\u001b[1;32m      9\u001b[0m                               deletes\u001b[39m=\u001b[39;49m[])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ds4ml/dataset.py:257\u001b[0m, in \u001b[0;36mDataSet.synthesize\u001b[0;34m(self, epsilon, degree, pseudonyms, deletes, retains, records)\u001b[0m\n\u001b[1;32m    254\u001b[0m records \u001b[39m=\u001b[39m records \u001b[39mif\u001b[39;00m records \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_records\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_bayesian_network(\n\u001b[1;32m    258\u001b[0m         epsilon, degree\u001b[39m=\u001b[39;49mdegree, pseudonyms\u001b[39m=\u001b[39;49mpseudonyms, deletes\u001b[39m=\u001b[39;49mdeletes,\n\u001b[1;32m    259\u001b[0m         retains\u001b[39m=\u001b[39;49mretains)\n\u001b[1;32m    261\u001b[0m \u001b[39m# if bayesian network is None, and probability is not None, that means\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m# there is only one column in the dataset.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39m# this is the only column label in this dataset\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ds4ml/dataset.py:210\u001b[0m, in \u001b[0;36mDataSet._construct_bayesian_network\u001b[0;34m(self, epsilon, degree, pseudonyms, deletes, retains)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, probability\n\u001b[1;32m    205\u001b[0m \u001b[39m# Bayesian network is defined as a set of AP (attribute-parent) pairs.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m# e.g. [(x1, p1), (x2, p2), ...], and pi is the parents of xi.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m# The algorithm follows the composability property of differential\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m# privacy, so the privacy budget is split to two parts.\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m network \u001b[39m=\u001b[39m greedy_bayes(indexes, epsilon \u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m, degree\u001b[39m=\u001b[39;49mdegree,\n\u001b[1;32m    211\u001b[0m                        retains\u001b[39m=\u001b[39;49mretains)\n\u001b[1;32m    212\u001b[0m cond_prs \u001b[39m=\u001b[39m noisy_conditionals(network, indexes, epsilon \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m network, cond_prs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ds4ml/synthesizer.py:143\u001b[0m, in \u001b[0;36mgreedy_bayes\u001b[0;34m(dataset, epsilon, degree, retains)\u001b[0m\n\u001b[1;32m    140\u001b[0m tasks \u001b[39m=\u001b[39m [(child, columns, n_parents, index, dataset) \u001b[39mfor\u001b[39;00m child, index \u001b[39min\u001b[39;00m\n\u001b[1;32m    141\u001b[0m          product(left_cols, \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(columns) \u001b[39m-\u001b[39m n_parents \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))]\n\u001b[1;32m    142\u001b[0m \u001b[39m# TODO: should use thread pool for large data set?\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m candidates \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(candidate_pairs, tasks))\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m ap, mi \u001b[39min\u001b[39;00m candidates:\n\u001b[1;32m    145\u001b[0m     aps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m ap\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ds4ml/synthesizer.py:85\u001b[0m, in \u001b[0;36mcandidate_pairs\u001b[0;34m(paras)\u001b[0m\n\u001b[1;32m     83\u001b[0m         aps\u001b[39m.\u001b[39mappend((child, parents))\n\u001b[1;32m     84\u001b[0m         \u001b[39m# TODO duplicate calculation of mutual information\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m         mi \u001b[39m=\u001b[39m mutual_information(dataset[child], dataset[parents])\n\u001b[1;32m     86\u001b[0m         mis\u001b[39m.\u001b[39mappend(mi)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m aps, mis\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ds4ml/utils.py:379\u001b[0m, in \u001b[0;36mmutual_information\u001b[0;34m(child, parents)\u001b[0m\n\u001b[1;32m    377\u001b[0m     parents \u001b[39m=\u001b[39m parents\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m    378\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     parents \u001b[39m=\u001b[39m parents\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(x\u001b[39m.\u001b[39;49marray), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    380\u001b[0m \u001b[39mreturn\u001b[39;00m mutual_info_score(child, parents)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:9558\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9547\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9549\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9550\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9551\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9556\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9557\u001b[0m )\n\u001b[0;32m-> 9558\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:741\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 741\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:871\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    868\u001b[0m results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_series_generator()\n\u001b[1;32m    870\u001b[0m \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:906\u001b[0m, in \u001b[0;36mFrameApply.wrap_results\u001b[0;34m(self, results, res_index)\u001b[0m\n\u001b[1;32m    904\u001b[0m constructor_sliced \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_constructor_sliced\n\u001b[1;32m    905\u001b[0m \u001b[39mif\u001b[39;00m constructor_sliced \u001b[39mis\u001b[39;00m Series:\n\u001b[0;32m--> 906\u001b[0m     result \u001b[39m=\u001b[39m create_series_with_explicit_dtype(\n\u001b[1;32m    907\u001b[0m         results, dtype_if_empty\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64\n\u001b[1;32m    908\u001b[0m     )\n\u001b[1;32m    909\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m     result \u001b[39m=\u001b[39m constructor_sliced(results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/construction.py:916\u001b[0m, in \u001b[0;36mcreate_series_with_explicit_dtype\u001b[0;34m(data, index, dtype, name, copy, fastpath, dtype_if_empty)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m is_empty_data(data) \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_if_empty\n\u001b[0;32m--> 916\u001b[0m \u001b[39mreturn\u001b[39;00m Series(\n\u001b[1;32m    917\u001b[0m     data\u001b[39m=\u001b[39;49mdata, index\u001b[39m=\u001b[39;49mindex, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, copy\u001b[39m=\u001b[39;49mcopy, fastpath\u001b[39m=\u001b[39;49mfastpath\n\u001b[1;32m    918\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:437\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    435\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m is_dict_like(data):\n\u001b[0;32m--> 437\u001b[0m     data, index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_dict(data, index, dtype)\n\u001b[1;32m    438\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:530\u001b[0m, in \u001b[0;36mSeries._init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    525\u001b[0m     keys, values \u001b[39m=\u001b[39m (), []\n\u001b[1;32m    527\u001b[0m \u001b[39m# Input is now list-like, so rely on \"standard\" construction:\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \n\u001b[1;32m    529\u001b[0m \u001b[39m# TODO: passing np.float64 to not break anything yet. See GH-17261\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m s \u001b[39m=\u001b[39m create_series_with_explicit_dtype(\n\u001b[1;32m    531\u001b[0m     \u001b[39m# error: Argument \"index\" to \"create_series_with_explicit_dtype\" has\u001b[39;49;00m\n\u001b[1;32m    532\u001b[0m     \u001b[39m# incompatible type \"Tuple[Any, ...]\"; expected \"Union[ExtensionArray,\u001b[39;49;00m\n\u001b[1;32m    533\u001b[0m     \u001b[39m# ndarray, Index, None]\"\u001b[39;49;00m\n\u001b[1;32m    534\u001b[0m     values,\n\u001b[1;32m    535\u001b[0m     index\u001b[39m=\u001b[39;49mkeys,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    536\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    537\u001b[0m     dtype_if_empty\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    538\u001b[0m )\n\u001b[1;32m    540\u001b[0m \u001b[39m# Now we just make sure the order is respected, if any\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mand\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/construction.py:916\u001b[0m, in \u001b[0;36mcreate_series_with_explicit_dtype\u001b[0;34m(data, index, dtype, name, copy, fastpath, dtype_if_empty)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m is_empty_data(data) \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_if_empty\n\u001b[0;32m--> 916\u001b[0m \u001b[39mreturn\u001b[39;00m Series(\n\u001b[1;32m    917\u001b[0m     data\u001b[39m=\u001b[39;49mdata, index\u001b[39m=\u001b[39;49mindex, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, copy\u001b[39m=\u001b[39;49mcopy, fastpath\u001b[39m=\u001b[39;49mfastpath\n\u001b[1;32m    918\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:400\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[39m# uncomment the line below when removing the FutureWarning\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[39m# dtype = np.dtype(object)\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m     data \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:7371\u001b[0m, in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7369\u001b[0m         \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39m_with_infer(index_like, copy\u001b[39m=\u001b[39mcopy, tupleize_cols\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   7370\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 7371\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49m_with_infer(index_like, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:718\u001b[0m, in \u001b[0;36mIndex._with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    717\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*the Index constructor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 718\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    720\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m _dtype_obj \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_is_multi:\n\u001b[1;32m    721\u001b[0m     \u001b[39m# error: Argument 1 to \"maybe_convert_objects\" has incompatible type\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[39m# \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     values \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result\u001b[39m.\u001b[39m_values)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:570\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m subarr \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39m_dtype_obj)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     \u001b[39m# with e.g. a list [1, 2, 3] casting to numeric is _not_ deprecated\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     subarr \u001b[39m=\u001b[39m _maybe_cast_data_without_dtype(\n\u001b[1;32m    571\u001b[0m         subarr, cast_numeric_deprecated\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m     )\n\u001b[1;32m    573\u001b[0m     dtype \u001b[39m=\u001b[39m subarr\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    574\u001b[0m \u001b[39mreturn\u001b[39;00m Index(subarr, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, name\u001b[39m=\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:7452\u001b[0m, in \u001b[0;36m_maybe_cast_data_without_dtype\u001b[0;34m(subarr, cast_numeric_deprecated)\u001b[0m\n\u001b[1;32m   7434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_cast_data_without_dtype\u001b[39m(\n\u001b[1;32m   7435\u001b[0m     subarr: np\u001b[39m.\u001b[39mndarray, cast_numeric_deprecated: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   7436\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[1;32m   7437\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7438\u001b[0m \u001b[39m    If we have an arraylike input but no passed dtype, try to infer\u001b[39;00m\n\u001b[1;32m   7439\u001b[0m \u001b[39m    a supported dtype.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7449\u001b[0m \u001b[39m    np.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   7450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 7452\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmaybe_convert_objects(\n\u001b[1;32m   7453\u001b[0m         subarr,\n\u001b[1;32m   7454\u001b[0m         convert_datetime\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   7455\u001b[0m         convert_timedelta\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   7456\u001b[0m         convert_period\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   7457\u001b[0m         convert_interval\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   7458\u001b[0m         dtype_if_all_nat\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mdatetime64[ns]\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   7459\u001b[0m     )\n\u001b[1;32m   7460\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   7461\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cast_numeric_deprecated:\n\u001b[1;32m   7462\u001b[0m             \u001b[39m# i.e. we started with a list, not an ndarray[object]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "synthetise(df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
